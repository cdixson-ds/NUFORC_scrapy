{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "ufo_by_char.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ws10ljqALYWy"
      },
      "source": [
        "#using tutorial https://www.tensorflow.org/tutorials/text/text_generation#advanced_customized_training "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cuoIaLhMy2VI"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "#more imports\n",
        "from tensorflow.keras.callbacks import LambdaCallback\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "import random\n",
        "import sys\n",
        "import os\n",
        "import time\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_tf0I3kgLJ0"
      },
      "source": [
        "#for saving the model\r\n",
        "!pip install -q pyyaml h5py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uNpVhQWDzXHc"
      },
      "source": [
        "# Read in the data\n",
        "df = pd.read_csv(\"ufo_update.csv\")\n",
        "text_ = \" \""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "id": "Je5J_-mSzYwj",
        "outputId": "dffdc089-a349-411d-e0de-7dd20eccf405"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>stats</th>\n",
              "      <th>date_time</th>\n",
              "      <th>report_link</th>\n",
              "      <th>city</th>\n",
              "      <th>state</th>\n",
              "      <th>shape</th>\n",
              "      <th>duration</th>\n",
              "      <th>summary</th>\n",
              "      <th>posted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The background is a blue sky.  The shape of th...</td>\n",
              "      <td>Occurred : 8/5/2020 10:15  (Entered as : 08/05...</td>\n",
              "      <td>8/5/20 10:15</td>\n",
              "      <td>http://www.nuforc.org/webreports/158/S158217.html</td>\n",
              "      <td>Ty Ty</td>\n",
              "      <td>GA</td>\n",
              "      <td>Unknown</td>\n",
              "      <td>5 minutes</td>\n",
              "      <td>The background is a blue sky. The shape of the...</td>\n",
              "      <td>8/6/20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Black polygonal craft with lights wobbling thr...</td>\n",
              "      <td>Occurred : 8/5/2020 18:50  (Entered as : 08/05...</td>\n",
              "      <td>8/5/20 18:50</td>\n",
              "      <td>http://www.nuforc.org/webreports/158/S158226.html</td>\n",
              "      <td>New Braunfels</td>\n",
              "      <td>TX</td>\n",
              "      <td>Chevron</td>\n",
              "      <td>2-3 minutes</td>\n",
              "      <td>Black polygonal craft with lights wobbling thr...</td>\n",
              "      <td>8/6/20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I observed a white ball of light flying from t...</td>\n",
              "      <td>Occurred : 8/4/2020 20:30  (Entered as : 08/04...</td>\n",
              "      <td>8/4/20 20:30</td>\n",
              "      <td>http://www.nuforc.org/webreports/158/S158228.html</td>\n",
              "      <td>Mesa</td>\n",
              "      <td>AZ</td>\n",
              "      <td>Circle</td>\n",
              "      <td>2 minutes</td>\n",
              "      <td>I observed a white ball of light flying from t...</td>\n",
              "      <td>8/6/20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>High altitude fast moving delta shaped flames ...</td>\n",
              "      <td>Occurred : 8/4/2020 22:00  (Entered as : 08/04...</td>\n",
              "      <td>8/4/20 22:00</td>\n",
              "      <td>http://www.nuforc.org/webreports/158/S158221.html</td>\n",
              "      <td>Miami Beach</td>\n",
              "      <td>FL</td>\n",
              "      <td>Fireball</td>\n",
              "      <td>1 minute</td>\n",
              "      <td>High altitude fast moving delta shaped flames....</td>\n",
              "      <td>8/6/20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Three unmistakable lights moving at a speed th...</td>\n",
              "      <td>Occurred : 8/5/2020 04:33  (Entered as : 08/05...</td>\n",
              "      <td>8/5/20 04:33</td>\n",
              "      <td>http://www.nuforc.org/webreports/158/S158220.html</td>\n",
              "      <td>Pheonix</td>\n",
              "      <td>AZ</td>\n",
              "      <td>Triangle</td>\n",
              "      <td>3 seconds</td>\n",
              "      <td>Three unmistakable lights moving at a speed th...</td>\n",
              "      <td>8/6/20</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  ...  posted\n",
              "0  The background is a blue sky.  The shape of th...  ...  8/6/20\n",
              "1  Black polygonal craft with lights wobbling thr...  ...  8/6/20\n",
              "2  I observed a white ball of light flying from t...  ...  8/6/20\n",
              "3  High altitude fast moving delta shaped flames ...  ...  8/6/20\n",
              "4  Three unmistakable lights moving at a speed th...  ...  8/6/20\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "0b9TbJ5Jzbuj",
        "outputId": "95e03f72-ad86-4860-a046-df4669d0ee33"
      },
      "source": [
        "df['text'][0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'The background is a blue sky.  The shape of the UFO is indescribable. UFO was moving from north to south at about tree top level at a very slow speed as if looking for something.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QJdd_5bojrR3",
        "outputId": "b1d0d2fc-7705-4226-d9f1-f067d0b63a46"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(93817, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZdkQ-pj7cOBk"
      },
      "source": [
        "#sub = df.sample(frac=.5)\n",
        "\n",
        "sub = df.iloc[:1000]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "id": "mzR5bdKNhU0T",
        "outputId": "114dc7ea-e459-4b07-eab6-192b10c41941"
      },
      "source": [
        "sub.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>stats</th>\n",
              "      <th>date_time</th>\n",
              "      <th>report_link</th>\n",
              "      <th>city</th>\n",
              "      <th>state</th>\n",
              "      <th>shape</th>\n",
              "      <th>duration</th>\n",
              "      <th>summary</th>\n",
              "      <th>posted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The background is a blue sky.  The shape of th...</td>\n",
              "      <td>Occurred : 8/5/2020 10:15  (Entered as : 08/05...</td>\n",
              "      <td>8/5/20 10:15</td>\n",
              "      <td>http://www.nuforc.org/webreports/158/S158217.html</td>\n",
              "      <td>Ty Ty</td>\n",
              "      <td>GA</td>\n",
              "      <td>Unknown</td>\n",
              "      <td>5 minutes</td>\n",
              "      <td>The background is a blue sky. The shape of the...</td>\n",
              "      <td>8/6/20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Black polygonal craft with lights wobbling thr...</td>\n",
              "      <td>Occurred : 8/5/2020 18:50  (Entered as : 08/05...</td>\n",
              "      <td>8/5/20 18:50</td>\n",
              "      <td>http://www.nuforc.org/webreports/158/S158226.html</td>\n",
              "      <td>New Braunfels</td>\n",
              "      <td>TX</td>\n",
              "      <td>Chevron</td>\n",
              "      <td>2-3 minutes</td>\n",
              "      <td>Black polygonal craft with lights wobbling thr...</td>\n",
              "      <td>8/6/20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I observed a white ball of light flying from t...</td>\n",
              "      <td>Occurred : 8/4/2020 20:30  (Entered as : 08/04...</td>\n",
              "      <td>8/4/20 20:30</td>\n",
              "      <td>http://www.nuforc.org/webreports/158/S158228.html</td>\n",
              "      <td>Mesa</td>\n",
              "      <td>AZ</td>\n",
              "      <td>Circle</td>\n",
              "      <td>2 minutes</td>\n",
              "      <td>I observed a white ball of light flying from t...</td>\n",
              "      <td>8/6/20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>High altitude fast moving delta shaped flames ...</td>\n",
              "      <td>Occurred : 8/4/2020 22:00  (Entered as : 08/04...</td>\n",
              "      <td>8/4/20 22:00</td>\n",
              "      <td>http://www.nuforc.org/webreports/158/S158221.html</td>\n",
              "      <td>Miami Beach</td>\n",
              "      <td>FL</td>\n",
              "      <td>Fireball</td>\n",
              "      <td>1 minute</td>\n",
              "      <td>High altitude fast moving delta shaped flames....</td>\n",
              "      <td>8/6/20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Three unmistakable lights moving at a speed th...</td>\n",
              "      <td>Occurred : 8/5/2020 04:33  (Entered as : 08/05...</td>\n",
              "      <td>8/5/20 04:33</td>\n",
              "      <td>http://www.nuforc.org/webreports/158/S158220.html</td>\n",
              "      <td>Pheonix</td>\n",
              "      <td>AZ</td>\n",
              "      <td>Triangle</td>\n",
              "      <td>3 seconds</td>\n",
              "      <td>Three unmistakable lights moving at a speed th...</td>\n",
              "      <td>8/6/20</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  ...  posted\n",
              "0  The background is a blue sky.  The shape of th...  ...  8/6/20\n",
              "1  Black polygonal craft with lights wobbling thr...  ...  8/6/20\n",
              "2  I observed a white ball of light flying from t...  ...  8/6/20\n",
              "3  High altitude fast moving delta shaped flames ...  ...  8/6/20\n",
              "4  Three unmistakable lights moving at a speed th...  ...  8/6/20\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kfAFO-C159TY",
        "outputId": "8052e46d-c7e6-42b1-aad3-5cb7be0dc18c"
      },
      "source": [
        "sub['text'] = sub['text'].astype(str)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "02GIXVWUQCV4"
      },
      "source": [
        "text = ' '.join(sub['text'].tolist())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ble0euwOTRC"
      },
      "source": [
        "#Clean text\r\n",
        "\r\n",
        "import re\r\n",
        "from bs4 import BeautifulSoup\r\n",
        "\r\n",
        "def cleanText(txt):\r\n",
        "    txt = BeautifulSoup(txt).get_text()\r\n",
        "    txt = txt.replace('\\t', '')\r\n",
        "    txt = txt.replace('\\x9d', '')\r\n",
        "    txt = txt.replace('\\xa0', '')\r\n",
        "    #remove all non letters from text\r\n",
        "    txt = re.sub(\"[^A-Za-z0-9_.,!'/$]\", \" \", txt) \r\n",
        "    txt = txt.split()\r\n",
        "    txt = \" \".join(txt)\r\n",
        "\r\n",
        "    return txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2CsUOo6RQAYy"
      },
      "source": [
        "text = cleanText(text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rk1NK8bx8q5k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "374159bb-f847-4822-ba6c-0a8e6b46208e"
      },
      "source": [
        "# Encode the data as Chars\n",
        "\n",
        "#get all unique chars\n",
        "chars = sorted(list(set(text)))\n",
        "print('unique characters', format(len(chars)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "unique characters 70\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "deut8LJ3MHiU"
      },
      "source": [
        "#create a mapping from unique characters to indices\r\n",
        "\r\n",
        "char_indices = {u:i for i, u in enumerate(chars)}\r\n",
        "indices_char = np.array(chars)\r\n",
        "\r\n",
        "text_as_int = np.array([char_indices[c] for c in text])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6il9wQF1Nw4M",
        "outputId": "ce0dc02b-57c3-477f-f4b9-921ef02dc778"
      },
      "source": [
        "print('{')\r\n",
        "for char,_ in zip(char_indices, range(70)):\r\n",
        "    print('  {:4s}: {:3d},'.format(repr(char), char_indices[char]))\r\n",
        "print('  ...\\n}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{\n",
            "  ' ' :   0,\n",
            "  '!' :   1,\n",
            "  '$' :   2,\n",
            "  \"'\" :   3,\n",
            "  ',' :   4,\n",
            "  '.' :   5,\n",
            "  '/' :   6,\n",
            "  '0' :   7,\n",
            "  '1' :   8,\n",
            "  '2' :   9,\n",
            "  '3' :  10,\n",
            "  '4' :  11,\n",
            "  '5' :  12,\n",
            "  '6' :  13,\n",
            "  '7' :  14,\n",
            "  '8' :  15,\n",
            "  '9' :  16,\n",
            "  'A' :  17,\n",
            "  'B' :  18,\n",
            "  'C' :  19,\n",
            "  'D' :  20,\n",
            "  'E' :  21,\n",
            "  'F' :  22,\n",
            "  'G' :  23,\n",
            "  'H' :  24,\n",
            "  'I' :  25,\n",
            "  'J' :  26,\n",
            "  'K' :  27,\n",
            "  'L' :  28,\n",
            "  'M' :  29,\n",
            "  'N' :  30,\n",
            "  'O' :  31,\n",
            "  'P' :  32,\n",
            "  'Q' :  33,\n",
            "  'R' :  34,\n",
            "  'S' :  35,\n",
            "  'T' :  36,\n",
            "  'U' :  37,\n",
            "  'V' :  38,\n",
            "  'W' :  39,\n",
            "  'X' :  40,\n",
            "  'Y' :  41,\n",
            "  'Z' :  42,\n",
            "  '_' :  43,\n",
            "  'a' :  44,\n",
            "  'b' :  45,\n",
            "  'c' :  46,\n",
            "  'd' :  47,\n",
            "  'e' :  48,\n",
            "  'f' :  49,\n",
            "  'g' :  50,\n",
            "  'h' :  51,\n",
            "  'i' :  52,\n",
            "  'j' :  53,\n",
            "  'k' :  54,\n",
            "  'l' :  55,\n",
            "  'm' :  56,\n",
            "  'n' :  57,\n",
            "  'o' :  58,\n",
            "  'p' :  59,\n",
            "  'q' :  60,\n",
            "  'r' :  61,\n",
            "  's' :  62,\n",
            "  't' :  63,\n",
            "  'u' :  64,\n",
            "  'v' :  65,\n",
            "  'w' :  66,\n",
            "  'x' :  67,\n",
            "  'y' :  68,\n",
            "  'z' :  69,\n",
            "  ...\n",
            "}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pGmV5v-JQZ_h",
        "outputId": "d823c0a7-31d4-4a2e-cc27-ccaacb602427"
      },
      "source": [
        "# The maximum length sentence you want for a single input in characters\r\n",
        "\r\n",
        "seq_length = 100   #try adjusting sequence length\r\n",
        "examples_per_epoch = len(text)//(seq_length+1)\r\n",
        "\r\n",
        "# Create training examples / targets\r\n",
        "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\r\n",
        "\r\n",
        "for i in char_dataset.take(5):\r\n",
        "    print(indices_char[i.numpy()])   #do not alias numpy as np"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "T\n",
            "h\n",
            "e\n",
            " \n",
            "b\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_enOcFOcUce6",
        "outputId": "17d0d874-fddf-44aa-dd12-9a9042029294"
      },
      "source": [
        "#The batch method lets us easily convert these individual characters to sequences of the desired size.\r\n",
        "\r\n",
        "sequences = char_dataset.batch(seq_length+1, drop_remainder=True)\r\n",
        "\r\n",
        "for item in sequences.take(5):\r\n",
        "  print(repr(''.join(indices_char[item.numpy()])))  #do not alias numpy as np"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'The background is a blue sky. The shape of the UFO is indescribable. UFO was moving from north to sou'\n",
            "'th at about tree top level at a very slow speed as if looking for something. Black polygonal craft wi'\n",
            "'th lights wobbling through sky. I was in the back yard area of my apartment complex with only my dog '\n",
            "'when I saw what I thought was a drone. 1 solid black object that appeared to be a pentagonal pyramid '\n",
            "'flying slowly through the air. It looked to be about the size of a small car and less than 1000ft or '\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8EsQHBrsWw-z"
      },
      "source": [
        "#For each sequence, duplicate and shift it to form the input and target text by \r\n",
        "#using the map method to apply a simple function to each batch:\r\n",
        "\r\n",
        "def split_input_target(chunk):\r\n",
        "    input_text = chunk[:-1]\r\n",
        "    target_text = chunk[1:]\r\n",
        "    return input_text, target_text\r\n",
        "\r\n",
        "dataset = sequences.map(split_input_target)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tBe2CejSW-nA",
        "outputId": "7a354a19-0b52-4f28-e8f0-7bd3e1419010"
      },
      "source": [
        "#Print the first example input and target values:\r\n",
        "\r\n",
        "for input_example, target_example in  dataset.take(1):\r\n",
        "    print('Input data: ', repr(''.join(indices_char[input_example.numpy()])))\r\n",
        "    print('Target data:', repr(''.join(indices_char[target_example.numpy()])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input data:  'The background is a blue sky. The shape of the UFO is indescribable. UFO was moving from north to so'\n",
            "Target data: 'he background is a blue sky. The shape of the UFO is indescribable. UFO was moving from north to sou'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GwEK0pH0YU_S",
        "outputId": "120f11fc-df37-42f3-98e0-0e97d6c6b812"
      },
      "source": [
        "#each index of these vectors is processed as a one time step. For the input at\r\n",
        "#time step 0, the model receives the index for 'T' and tries to predict the\r\n",
        "#index for i as the next character. At the next timestep, it does the same thing\r\n",
        "#but the RNN considers the previous step context in addition to the current input\r\n",
        "#character\r\n",
        "\r\n",
        "for i, (input_idx, target_idx) in enumerate(zip(input_example[:5], target_example[:5])):\r\n",
        "    print(\"Step {:4d}\".format(i))\r\n",
        "    print(\"  input: {} ({:s})\".format(input_idx, repr(indices_char[input_idx])))\r\n",
        "    print(\"  expected output: {} ({:s})\".format(target_idx, repr(indices_char[target_idx])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Step    0\n",
            "  input: 36 ('T')\n",
            "  expected output: 51 ('h')\n",
            "Step    1\n",
            "  input: 51 ('h')\n",
            "  expected output: 48 ('e')\n",
            "Step    2\n",
            "  input: 48 ('e')\n",
            "  expected output: 0 (' ')\n",
            "Step    3\n",
            "  input: 0 (' ')\n",
            "  expected output: 45 ('b')\n",
            "Step    4\n",
            "  input: 45 ('b')\n",
            "  expected output: 44 ('a')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xgA8opVIZKD1",
        "outputId": "38ce232e-eb25-49f9-c792-1d75804f09f1"
      },
      "source": [
        "#Create training batches - you can use tf.data to split the text into manageable\r\n",
        "#sequences. But before feeding this data into the model, you need to shuffle the\r\n",
        "#data and pack it into batches\r\n",
        "\r\n",
        "# Batch size\r\n",
        "BATCH_SIZE = 64\r\n",
        "\r\n",
        "# Buffer size to shuffle the dataset\r\n",
        "# (TF data is designed to work with possibly infinite sequences,\r\n",
        "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\r\n",
        "# it maintains a buffer in which it shuffles elements).\r\n",
        "BUFFER_SIZE = 10000\r\n",
        "\r\n",
        "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\r\n",
        "\r\n",
        "dataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BatchDataset shapes: ((64, 100), (64, 100)), types: (tf.int64, tf.int64)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OyIAOv_Dirgy"
      },
      "source": [
        "Build the model\r\n",
        "For each character the model looks up the embedding, runs the GRU one timestep\r\n",
        "with the embedding as input, and applies the dense layer to generate logits\r\n",
        "predicting the log-likelihood of the next character"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-svJLMj4Zh9h"
      },
      "source": [
        "# Length of the vocabulary in chars\r\n",
        "vocab_size = len(chars)\r\n",
        "\r\n",
        "# The embedding dimension\r\n",
        "embedding_dim = 256\r\n",
        "\r\n",
        "# Number of RNN units\r\n",
        "rnn_units = 1024"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2yhDhLqxdEtV"
      },
      "source": [
        "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\r\n",
        "    model = tf.keras.Sequential([\r\n",
        "        tf.keras.layers.Embedding(vocab_size, embedding_dim,\r\n",
        "                                  batch_input_shape=[batch_size, None]),\r\n",
        "        tf.keras.layers.GRU(rnn_units,\r\n",
        "                            return_sequences=True,\r\n",
        "                            stateful=True,\r\n",
        "                            recurrent_initializer='glorot_uniform'),\r\n",
        "        tf.keras.layers.Dense(vocab_size)\r\n",
        "    ])\r\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G0CpuU3idJMq"
      },
      "source": [
        "model = build_model(\r\n",
        "    vocab_size=len(chars),\r\n",
        "    embedding_dim=embedding_dim,\r\n",
        "    rnn_units=rnn_units,\r\n",
        "    batch_size=BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_CsdktNrdviW",
        "outputId": "fdd94c8d-be0f-4807-cc9c-469f5c3f4ead"
      },
      "source": [
        "#check the shape of the output\r\n",
        "\r\n",
        "for input_example_batch, target_example_batch in dataset.take(1):\r\n",
        "    example_batch_predictions = model(input_example_batch)\r\n",
        "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length,vocab_size)\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(64, 100, 70) # (batch_size, sequence_length,vocab_size)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PC6h-PPsd_Y6",
        "outputId": "f1bbec48-3c4a-4555-9408-56cc2125daa4"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (64, None, 256)           17920     \n",
            "_________________________________________________________________\n",
            "gru (GRU)                    (64, None, 1024)          3938304   \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (64, None, 70)            71750     \n",
            "=================================================================\n",
            "Total params: 4,027,974\n",
            "Trainable params: 4,027,974\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vZj_eLAueXkk",
        "outputId": "a9ca5528-1424-4c44-c6a2-0aba06569610"
      },
      "source": [
        "#to get prediction from the model you need to sample from the output \r\n",
        "#distribution to get actual character indices\r\n",
        "\r\n",
        "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\r\n",
        "sampled_indices = tf.squeeze(sampled_indices,axis=-1).numpy()\r\n",
        "\r\n",
        "sampled_indices"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([40, 41, 30, 64, 20,  7,  6, 58, 11, 22, 26, 10,  4, 49, 69, 43, 22,\n",
              "       64, 27, 62, 67, 34, 55,  4, 16, 17, 29, 17,  0, 53, 54, 60, 62, 11,\n",
              "       26,  1, 45, 41, 64, 29, 69, 25, 46,  1, 13, 27, 23, 38, 41, 15, 46,\n",
              "       28,  3, 21, 13, 45, 14, 20, 14, 28, 62, 64, 63, 39, 24, 10, 18, 55,\n",
              "        0, 48, 12,  0, 16,  9, 61, 46,  7, 15, 69, 14, 20, 38,  8, 53, 66,\n",
              "       41, 60,  6, 15,  2, 53, 19, 30, 27,  0, 36, 13,  7, 48, 62])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9jLZvLQwfAqI",
        "outputId": "f06e201b-3222-4d3f-8188-20eb2663c04f"
      },
      "source": [
        "#decode these to see the text predicted by this untrained model\r\n",
        "\r\n",
        "print(\"Input: \\n\", repr(\"\".join(indices_char[input_example_batch[0]])))\r\n",
        "print()\r\n",
        "print(\"Next Char Predictions: \\n\", repr(\"\".join(indices_char[sampled_indices ])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: \n",
            " 'ow frequently as a child. Over the years I have been bedazzled by dozens of sights similar to this o'\n",
            "\n",
            "Next Char Predictions: \n",
            " \"XYNuD0/o4FJ3,fz_FuKsxRl,9AMA jkqs4J!bYuMzIc!6KGVY8cL'E6b7D7LsutWH3Bl e5 92rc08z7DV1jwYq/8$jCNK T60es\"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GXHl4ugAfbRa",
        "outputId": "77eea393-1dee-4a6b-fa8e-729dcf38b847"
      },
      "source": [
        "#train the model - at this point problem can be treated as a standard\r\n",
        "#classification problem. Given the previous RNN state, and the input this time\r\n",
        "#step, predict the class of the next character\r\n",
        "\r\n",
        "def loss(labels, logits):\r\n",
        "    return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\r\n",
        "\r\n",
        "example_batch_loss = loss(target_example_batch, example_batch_predictions)\r\n",
        "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\r\n",
        "print(\"scalar_loss:      \", example_batch_loss.numpy().mean())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prediction shape:  (64, 100, 70)  # (batch_size, sequence_length, vocab_size)\n",
            "scalar_loss:       4.249167\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0EXdpb8f2on"
      },
      "source": [
        "#Configure the training procedure using the tf.keras.Model.compile method. \r\n",
        "#Use tf.keras.optimizers.Adam with default arguments and the loss function.\r\n",
        "\r\n",
        "model.compile(optimizer='adam', loss=loss, metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ViJLYLS_gFU9"
      },
      "source": [
        "#Use a tf.keras.callbacks.ModelCheckpoint to ensure that checkpoints \r\n",
        "#are saved during training:\r\n",
        "\r\n",
        "# Directory where the checkpoints will be saved\r\n",
        "checkpoint_dir = './training_checkpoints'\r\n",
        "# Name of the checkpoint files\r\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\r\n",
        "\r\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\r\n",
        "    filepath=checkpoint_prefix,\r\n",
        "    save_weights_only=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N3cFqo3CgO-e",
        "outputId": "65a05291-7b29-4d89-b827-e819733985aa"
      },
      "source": [
        "EPOCHS = 30\r\n",
        "\r\n",
        "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "97/97 [==============================] - 6s 42ms/step - loss: 3.5509 - accuracy: 0.1937\n",
            "Epoch 2/30\n",
            "97/97 [==============================] - 5s 41ms/step - loss: 2.1786 - accuracy: 0.3785\n",
            "Epoch 3/30\n",
            "97/97 [==============================] - 5s 41ms/step - loss: 1.8654 - accuracy: 0.4626\n",
            "Epoch 4/30\n",
            "97/97 [==============================] - 5s 41ms/step - loss: 1.6108 - accuracy: 0.5406\n",
            "Epoch 5/30\n",
            "97/97 [==============================] - 5s 41ms/step - loss: 1.4606 - accuracy: 0.5802\n",
            "Epoch 6/30\n",
            "97/97 [==============================] - 5s 41ms/step - loss: 1.3536 - accuracy: 0.6087\n",
            "Epoch 7/30\n",
            "97/97 [==============================] - 5s 41ms/step - loss: 1.2830 - accuracy: 0.6272\n",
            "Epoch 8/30\n",
            "97/97 [==============================] - 5s 41ms/step - loss: 1.2256 - accuracy: 0.6408\n",
            "Epoch 9/30\n",
            "97/97 [==============================] - 5s 41ms/step - loss: 1.1801 - accuracy: 0.6532\n",
            "Epoch 10/30\n",
            "97/97 [==============================] - 5s 41ms/step - loss: 1.1305 - accuracy: 0.6663\n",
            "Epoch 11/30\n",
            "97/97 [==============================] - 5s 41ms/step - loss: 1.0914 - accuracy: 0.6770\n",
            "Epoch 12/30\n",
            "97/97 [==============================] - 5s 41ms/step - loss: 1.0504 - accuracy: 0.6882\n",
            "Epoch 13/30\n",
            "97/97 [==============================] - 5s 41ms/step - loss: 1.0176 - accuracy: 0.6976\n",
            "Epoch 14/30\n",
            "97/97 [==============================] - 5s 41ms/step - loss: 0.9789 - accuracy: 0.7077\n",
            "Epoch 15/30\n",
            "97/97 [==============================] - 5s 41ms/step - loss: 0.9423 - accuracy: 0.7186\n",
            "Epoch 16/30\n",
            "97/97 [==============================] - 5s 41ms/step - loss: 0.9068 - accuracy: 0.7288\n",
            "Epoch 17/30\n",
            "97/97 [==============================] - 5s 41ms/step - loss: 0.8678 - accuracy: 0.7417\n",
            "Epoch 18/30\n",
            "97/97 [==============================] - 5s 41ms/step - loss: 0.8303 - accuracy: 0.7534\n",
            "Epoch 19/30\n",
            "97/97 [==============================] - 5s 41ms/step - loss: 0.7929 - accuracy: 0.7649\n",
            "Epoch 20/30\n",
            "97/97 [==============================] - 5s 41ms/step - loss: 0.7532 - accuracy: 0.7789\n",
            "Epoch 21/30\n",
            "97/97 [==============================] - 5s 41ms/step - loss: 0.7155 - accuracy: 0.7910\n",
            "Epoch 22/30\n",
            "97/97 [==============================] - 5s 41ms/step - loss: 0.6795 - accuracy: 0.8042\n",
            "Epoch 23/30\n",
            "97/97 [==============================] - 5s 41ms/step - loss: 0.6431 - accuracy: 0.8163\n",
            "Epoch 24/30\n",
            "97/97 [==============================] - 5s 41ms/step - loss: 0.6101 - accuracy: 0.8287\n",
            "Epoch 25/30\n",
            "97/97 [==============================] - 5s 41ms/step - loss: 0.5800 - accuracy: 0.8400\n",
            "Epoch 26/30\n",
            "97/97 [==============================] - 5s 41ms/step - loss: 0.5523 - accuracy: 0.8483\n",
            "Epoch 27/30\n",
            "97/97 [==============================] - 5s 41ms/step - loss: 0.5260 - accuracy: 0.8582\n",
            "Epoch 28/30\n",
            "97/97 [==============================] - 5s 41ms/step - loss: 0.5057 - accuracy: 0.8661\n",
            "Epoch 29/30\n",
            "97/97 [==============================] - 5s 41ms/step - loss: 0.4857 - accuracy: 0.8735\n",
            "Epoch 30/30\n",
            "97/97 [==============================] - 5s 41ms/step - loss: 0.4668 - accuracy: 0.8792\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bxmnObfkimYm"
      },
      "source": [
        "Generate text - to keep prediction step simple use a batch size of 1\r\n",
        "because of the way the RNN state is passed from timestep to timestep, the \r\n",
        "model only accepts a fixed batch size once built. To run the model with a diff\r\n",
        "batch size, you need to rebuild the model and restore the weights from the checkpoint. \r\n",
        "\r\n",
        "Looking at the genearated text, the model knows when to capitalize, make\r\n",
        "paragraphs and imitate the vocabulary. With a small # of epochs it has not learned to form coherent sentences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "gD_RtjpdgdIt",
        "outputId": "00cf38c6-e63f-4506-b830-2631623ff04b"
      },
      "source": [
        "tf.train.latest_checkpoint(checkpoint_dir)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'./training_checkpoints/ckpt_30'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5eFBGQ54g8h7"
      },
      "source": [
        "model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\r\n",
        "\r\n",
        "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\r\n",
        "\r\n",
        "model.build(tf.TensorShape([1, None]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OX_mOUmWg_NT",
        "outputId": "57a8585e-c96a-499d-95a4-70b5ea4cdfe3"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (1, None, 256)            17920     \n",
            "_________________________________________________________________\n",
            "gru_1 (GRU)                  (1, None, 1024)           3938304   \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (1, None, 70)             71750     \n",
            "=================================================================\n",
            "Total params: 4,027,974\n",
            "Trainable params: 4,027,974\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FhPmP1N0oyB6"
      },
      "source": [
        "#save those weights\r\n",
        "\r\n",
        "model.save_weights(checkpoint_dir.format(epoch=0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "2TK6VB9-pRaV",
        "outputId": "79023906-36f0-41d5-c2f2-29c468a29c7a"
      },
      "source": [
        "latest = tf.train.latest_checkpoint(checkpoint_dir)\r\n",
        "latest"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'./training_checkpoints/ckpt_30'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WsGIuqTepuwd"
      },
      "source": [
        "#create and train new model instance\r\n",
        "\r\n",
        "model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RytWF0d4t3yT"
      },
      "source": [
        "model.fit(dataset, epochs=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gYI8VctBs4Yu"
      },
      "source": [
        "#save entire model to HDF5 file\r\n",
        "#the '.h5' extension indicates that the model should be saved to HDF5\r\n",
        "model.save('my_model.hf')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nAUjuX7qif9o"
      },
      "source": [
        "The prediction loop: the following code generates the text.\r\n",
        "begin by choosing a start string, initializing the RNN state and setting the \r\n",
        "number of characters to generate. Get the prediction distribution of the next\r\n",
        "character using the start string and the RNN state. Then use a categorical \r\n",
        "distribution to calculate the index of the predicted character. Use this\r\n",
        "predicted character as our next input to the model. The RNN state returned by \r\n",
        "the model is fed back into the model so that it now has more context, instead\r\n",
        "only one character. After predicting the next character, the modified RNN states\r\n",
        "are again fed back into the model, which is how it learns more context from the\r\n",
        "previously predicted characters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQkwgTwJiPlB"
      },
      "source": [
        "def generate_text(model, start_string):\r\n",
        "    # Evaluation step (generating text using the learned model)\r\n",
        "\r\n",
        "    # Number of characters to generate\r\n",
        "    num_generate = 1000\r\n",
        "\r\n",
        "    # Converting our start string to numbers (vectorizing)\r\n",
        "    input_eval = [char_indices[s] for s in start_string]\r\n",
        "    input_eval = tf.expand_dims(input_eval, 0)\r\n",
        "\r\n",
        "    # Empty string to store our results\r\n",
        "    text_generated = []\r\n",
        "\r\n",
        "    # Low temperature results in more predictable text.\r\n",
        "    # Higher temperature results in more surprising text.\r\n",
        "    # Experiment to find the best setting.\r\n",
        "    temperature = 1.0\r\n",
        "\r\n",
        "    # Here batch size == 1\r\n",
        "    model.reset_states()\r\n",
        "    for i in range(num_generate):\r\n",
        "        predictions = model(input_eval)\r\n",
        "        # remove the batch dimension\r\n",
        "        predictions = tf.squeeze(predictions, 0)\r\n",
        "\r\n",
        "        # using a categorical distribution to predict the character returned by the model\r\n",
        "        predictions = predictions / temperature\r\n",
        "        predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\r\n",
        "\r\n",
        "        # Pass the predicted character as the next input to the model\r\n",
        "        # along with the previous hidden state\r\n",
        "        input_eval = tf.expand_dims([predicted_id], 0)\r\n",
        "\r\n",
        "        text_generated.append(indices_char[predicted_id])\r\n",
        "\r\n",
        "    return (start_string + ''.join(text_generated))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4r5WyUgMjGMc"
      },
      "source": [
        "print(generate_text(model, start_string=u\"I saw a little green man \"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKXXEvYSbsXg"
      },
      "source": [
        "SAVE the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FmGZXJ-Oj9DU"
      },
      "source": [
        "# checkpoint_path = \"training_1/cp.ckpt\"\r\n",
        "# checkpoint_dir = os.path.dirname(checkpoint_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ffxBOjKAktPj"
      },
      "source": [
        "# Create a callback that saves the model's weights\r\n",
        "# cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\r\n",
        "#                                                  save_weights_only=True,\r\n",
        "#                                                  verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26QM3YpklhPz"
      },
      "source": [
        "model.compile(optimizer='adam', loss=loss, metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aM5AF8LSlDMl"
      },
      "source": [
        "# Train the model with the new callback\r\n",
        "model.fit(dataset,\r\n",
        "          epochs=EPOCHS,\r\n",
        "          callbacks=[checkpoint_callback])  # Pass callback to training"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZdwkQJ2lrwz"
      },
      "source": [
        "# model = build_model(\r\n",
        "#     vocab_size=len(chars),\r\n",
        "#     embedding_dim=embedding_dim,\r\n",
        "#     rnn_units=rnn_units,\r\n",
        "#     batch_size=BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-Y94pZYl2W1"
      },
      "source": [
        "# optimizer = tf.keras.optimizers.Adam()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E7OSbDbsl6Ey"
      },
      "source": [
        "# @tf.function\r\n",
        "# def train_step(inp, target):\r\n",
        "#     with tf.GradientTape() as tape:\r\n",
        "#         predictions = model(inp)\r\n",
        "#         loss = tf.reduce_mean(\r\n",
        "#             tf.keras.losses.sparse_categorical_crossentropy(\r\n",
        "#                 target, predictions, from_logits=True))\r\n",
        "#     grads = tape.gradient(loss, model.trainable_variables)\r\n",
        "#     optimizer.apply_gradients(zip(grads, model.trainable_variables))\r\n",
        "\r\n",
        "#     return loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DLMpdM5Xl-PC"
      },
      "source": [
        "# Training step\r\n",
        "# EPOCHS = 10\r\n",
        "\r\n",
        "# for epoch in range(EPOCHS):\r\n",
        "#     start = time.time()\r\n",
        "\r\n",
        "#     # resetting the hidden state at the start of every epoch\r\n",
        "#     model.reset_states()\r\n",
        "\r\n",
        "#     for (batch_n, (inp, target)) in enumerate(dataset):\r\n",
        "#         loss = train_step(inp, target)\r\n",
        "\r\n",
        "#         if batch_n % 100 == 0:\r\n",
        "#             template = 'Epoch {} Batch {} Loss {}'\r\n",
        "#             print(template.format(epoch + 1, batch_n, loss))\r\n",
        "\r\n",
        "#     # saving (checkpoint) the model every 5 epochs\r\n",
        "#     if (epoch + 1) % 5 == 0:\r\n",
        "#         model.save_weights(checkpoint_prefix.format(epoch=epoch))\r\n",
        "\r\n",
        "#     print('Epoch {} Loss {:.4f}'.format(epoch + 1, loss))\r\n",
        "#     print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))\r\n",
        "\r\n",
        "# model.save_weights(checkpoint_prefix.format(epoch=epoch))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BC4yhUp0MwXr"
      },
      "source": [
        "# from keras.optimizers import RMSprop\n",
        "# from keras.layers import Dense, Activation  #move later\n",
        "\n",
        "# model = Sequential()\n",
        "# model.add(LSTM(128, input_shape=(maxlen, len(chars))))\n",
        "# model.add(Dense(len(chars)))\n",
        "# model.add(Activation('softmax'))\n",
        "# optimizer = RMSprop(lr=0.01)\n",
        "# model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vwDl7MlnsBaA"
      },
      "source": [
        "# def sample(preds, temperature=1.0):\n",
        "#     # helper function to sample an index from a probability array\n",
        "#     preds = np.asarray(preds).astype('float64')\n",
        "#     preds = np.log(preds) / temperature\n",
        "#     exp_preds = np.exp(preds)\n",
        "#     preds = exp_preds / np.sum(exp_preds)\n",
        "#     probas = np.random.multinomial(1, preds, 1)\n",
        "#     return np.argmax(probas)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t1W3L_YCsFOM"
      },
      "source": [
        "# def on_epoch_end(epoch, _):\n",
        "#     # Function invoked at end of each epoch. Prints generated text.\n",
        "#     print()\n",
        "#     print('----- Generating text after Epoch: %d' % epoch)\n",
        "\n",
        "#     start_index = random.randint(0, len(text) - maxlen - 1)\n",
        "#     for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
        "#         print('----- diversity:', diversity)\n",
        "\n",
        "#         generated = ''\n",
        "#         sentence = text[start_index: start_index + maxlen]\n",
        "#         generated += sentence\n",
        "#         print('----- Generating with seed: \"' + sentence + '\"')\n",
        "#         sys.stdout.write(generated)\n",
        "\n",
        "#         for i in range(400):\n",
        "#             x_pred = np.zeros((1, maxlen, len(chars)))\n",
        "#             for t, char in enumerate(sentence):\n",
        "#                 x_pred[0, t, char_indices[char]] = 1.\n",
        "\n",
        "#             preds = model.predict(x_pred, verbose=0)[0]\n",
        "#             next_index = sample(preds, diversity)\n",
        "#             next_char = indices_char[next_index]\n",
        "\n",
        "#             generated += next_char\n",
        "#             sentence = sentence[1:] + next_char\n",
        "\n",
        "#             sys.stdout.write(next_char)\n",
        "#             sys.stdout.flush()\n",
        "#         print()\n",
        "\n",
        "# print_callback = LambdaCallback(on_epoch_end=on_epoch_end)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IGcVaeWzJzYf"
      },
      "source": [
        "# history_2 = model.fit(x, y,\n",
        "#           batch_size=128,\n",
        "#           epochs=100,\n",
        "#           callbacks=[print_callback])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FAXL6PvPsIO-"
      },
      "source": [
        "# history_3 = model.fit(x, y,\n",
        "#           batch_size=128,\n",
        "#           epochs=150,\n",
        "#           callbacks=[print_callback])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}